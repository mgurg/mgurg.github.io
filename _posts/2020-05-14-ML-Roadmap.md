---
layout: post
title: "Machine learning ü§ñ roadap"
categories: ML
author: "Micha≈Ç"
math: true
---



Zbi√≥r informacji o tym co ka≈ºdy m≈Çody adept ML i DataScience wiedzieƒá powinien. Temat jest rozleg≈Çy i nie mam jeszcze pomys≈Çu jak to dobrze ustrukturyzowaƒá, ale bƒôdƒô pr√≥bowa≈Ç.

[Newsletter Uczymy Maszyny](https://us20.campaign-archive.com/home/?u=75f8b217047c7703de3c71ca4&id=9ab9c19314)

# Mathematics

* Linear Algebra (Vectors; Norm of a vector; Matrices; Transpose of a matrix; The inverse of a matrix; The determinant of a matrix; Trace of a Matrix; Dot product; Eigenvalues; Eigenvectors)
* Probability Theory and Statistics (Mean, Median, Mode, Standard deviation/variance, Correlation coefficient and the covariance matrix, Probability distributions (Binomial, Poisson, Normal), p-value, Baye‚Äôs Theorem (Precision, Recall, Positive Predictive Value, Negative Predictive Value, Confusion Matrix, ROC Curve), Central Limit Theorem, R_2 score, Mean Square Error (MSE), A/B Testing, Monte Carlo Simulation)
* Multivariable Calculus (unctions of several variables; Derivatives and gradients; Step function, Sigmoid function, Logit function, ReLU (Rectified Linear Unit) function; Cost function; Plotting of functions; Minimum and Maximum values of a function)
* Optimization Methods (Cost function/Objective function; Likelihood function; Error function; Gradient Descent Algorithm and its variants (e.g. Stochastic Gradient Descent Algorithm))

# ML Roadmap

[A Tour of Machine Learning Algorithms](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)

Obrazkowa mapa: [ml-engineer-roadmap](https://github.com/chris-chris/ml-engineer-roadmap/blob/master/img/ml-engineer.png)

Learning Style

* Supervised Learning
* Unsupervised Learning
* Semi-Supervised Learning

Machine Learning Algorithms

* Regression Algorithms
  * Ordinary Least Squares Regression (OLSR)
  * Linear Regression
  * Logistic Regression
  * Stepwise Regression
  * Multivariate Adaptive Regression Splines (MARS)
  * Locally Estimated Scatterplot Smoothing (LOESS)
* Instance-based Algorithms
  * k-Nearest Neighbor (kNN)
  * Learning Vector Quantization (LVQ)
  * Self-Organizing Map (SOM)
  * Locally Weighted Learning (LWL)
  * Support Vector Machines (SVM)
* Regularization Algorithms
  * Ridge Regression
  * Least Absolute Shrinkage and Selection Operator (LASSO)
  * Elastic Net
  * Least-Angle Regression (LARS)
* Decision Tree Algorithms
  * Classification and Regression Tree (CART)
  * Iterative Dichotomiser 3 (ID3)
  * C4.5 and C5.0 (different versions of a powerful approach)
  * Chi-squared Automatic Interaction Detection (CHAID)
  * Decision Stump
  * M5
  * Conditional Decision Trees
* Bayesian Algorithms
  * Naive Bayes
  * Gaussian Naive Bayes
  * Multinomial Naive Bayes
  * Averaged One-Dependence Estimators (AODE)
  * Bayesian Belief Network (BBN)
  * Bayesian Network (BN)
* Clustering Algorithms
  * k-Means
  * k-Medians
  * Expectation Maximisation (EM)
  * Hierarchical Clustering
* Association Rule Learning Algorithms
  * Apriori algorithm
  * Eclat algorithm
* Artificial Neural Network Algorithms
  * Perceptron
  * Multilayer Perceptrons (MLP)
  * Back-Propagation
  * Stochastic Gradient Descent
  * Hopfield Network
  * Radial Basis Function Network (RBFN)
* Deep Learning Algorithms
  * Convolutional Neural Network (CNN)
  * Recurrent Neural Networks (RNNs)
  * Long Short-Term Memory Networks (LSTMs)
  * Stacked Auto-Encoders
  * Deep Boltzmann Machine (DBM)
  * Deep Belief Networks (DBN)
* Dimensionality Reduction Algorithms
  * Principal Component Analysis (PCA)
  * Principal Component Regression (PCR)
  * Partial Least Squares Regression (PLSR)
  * Sammon Mapping
  * Multidimensional Scaling (MDS)
  * Projection Pursuit
  * Linear Discriminant Analysis (LDA)
  * Mixture Discriminant Analysis (MDA)
  * Quadratic Discriminant Analysis (QDA)
  * Flexible Discriminant Analysis (FDA)
* Ensemble Algorithms
  * Boosting
  * Bootstrapped Aggregation (Bagging)
  * AdaBoost
  * Weighted Average (Blending)
  * Stacked Generalization (Stacking)
  * Gradient Boosting Machines (GBM)
  * Gradient Boosted Regression Trees (GBRT)
  * Random Forest
